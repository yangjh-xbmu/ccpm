# AIPM ä½¿ç”¨æŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹AIPMåŒ…ï¼Œäº†è§£å¦‚ä½•åœ¨é¡¹ç›®ä¸­ä½¿ç”¨å„ç§åŠŸèƒ½ã€‚

## ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [åŸºç¡€ç”¨æ³•](#åŸºç¡€ç”¨æ³•)
- [é«˜çº§ç”¨æ³•](#é«˜çº§ç”¨æ³•)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [ç¤ºä¾‹é¡¹ç›®](#ç¤ºä¾‹é¡¹ç›®)

## å¿«é€Ÿå¼€å§‹

### 1. é¡¹ç›®ç»“æ„å‡†å¤‡

é¦–å…ˆï¼Œç¡®ä¿æ‚¨çš„é¡¹ç›®å…·æœ‰ä»¥ä¸‹ç›®å½•ç»“æ„ï¼š

```
your-project/
â”œâ”€â”€ prds/           # PRDæ–‡æ¡£ç›®å½•
â”œâ”€â”€ epics/          # Epicæ–‡æ¡£ç›®å½•
â”œâ”€â”€ features/       # åŠŸèƒ½å¼€å‘ç›®å½•
â”‚   â””â”€â”€ feature-name/
â”‚       â”œâ”€â”€ tasks.md
â”‚       â”œâ”€â”€ backend/
â”‚       â”œâ”€â”€ frontend/
â”‚       â””â”€â”€ docs/
â””â”€â”€ aipm/          # AIPMåŒ…
```

### 2. åŸºæœ¬å¯¼å…¥

```python
# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from aipm.core.base import (
    BaseValidator,
    BaseFileManager,
    BaseWorkflowStep,
    BaseContentGenerator,
    BaseInteractionHandler
)

# å¯¼å…¥å‘½ä»¤æ¨¡å—
from aipm.commands.prd_new import PRDContentGenerator
from aipm.commands.epic_decompose import (
    TaskContentGenerator,
    TaskDecompositionHandler
)

# å¯¼å…¥AIæ¨¡å—
from aipm.ai.client import AIClient, AIPromptBuilder

# å¯¼å…¥å·¥å…·æ¨¡å—
from aipm.utils.helpers import (
    ContentExtractor,
    ContentFormatter,
    InteractionHelper,
    PathHelper
)
```

### 3. ç¬¬ä¸€ä¸ªç¤ºä¾‹

åˆ›å»ºä¸€ä¸ªç®€å•çš„PRDæ–‡æ¡£ï¼š

```python
from aipm.commands.prd_new import PRDContentGenerator
from aipm.core.base import BaseFileManager
from pathlib import Path

# åˆå§‹åŒ–ç»„ä»¶
generator = PRDContentGenerator()
file_manager = BaseFileManager()

# å®šä¹‰åŠŸèƒ½ä¿¡æ¯
feature_name = "user-profile"
answers = {
    'description': 'ç”¨æˆ·ä¸ªäººèµ„æ–™ç®¡ç†åŠŸèƒ½',
    'executive_summary': 'å…è®¸ç”¨æˆ·æŸ¥çœ‹å’Œç¼–è¾‘ä¸ªäººèµ„æ–™ä¿¡æ¯',
    'problem_statement': 'ç”¨æˆ·éœ€è¦èƒ½å¤Ÿç®¡ç†è‡ªå·±çš„ä¸ªäººä¿¡æ¯',
    'user_stories': [
        'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤ŸæŸ¥çœ‹æˆ‘çš„ä¸ªäººèµ„æ–™',
        'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿç¼–è¾‘æˆ‘çš„ä¸ªäººä¿¡æ¯',
        'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿä¸Šä¼ å¤´åƒ'
    ],
    'functional_requirements': [
        'æ˜¾ç¤ºç”¨æˆ·åŸºæœ¬ä¿¡æ¯',
        'æ”¯æŒä¿¡æ¯ç¼–è¾‘',
        'æ”¯æŒå¤´åƒä¸Šä¼ ',
        'æ•°æ®éªŒè¯'
    ],
    'non_functional_requirements': [
        'é¡µé¢åŠ è½½æ—¶é—´<3ç§’',
        'æ”¯æŒç§»åŠ¨ç«¯å“åº”å¼è®¾è®¡',
        'æ•°æ®åŠ å¯†å­˜å‚¨'
    ]
}

# ç”Ÿæˆå¹¶ä¿å­˜PRD
created_time = file_manager.get_current_datetime()
content = generator.generate_content(feature_name, answers, created_time)

prd_path = Path(f"prds/{feature_name}.md")
file_manager.ensure_directory(prd_path.parent)
file_manager.write_file(prd_path, content)

print(f"âœ… PRDå·²åˆ›å»º: {prd_path}")
```

## ç¯å¢ƒé…ç½®

### ç¯å¢ƒå˜é‡è®¾ç½®

å¦‚æœæ‚¨è®¡åˆ’ä½¿ç”¨AIåŠŸèƒ½ï¼Œéœ€è¦è®¾ç½®ç›¸åº”çš„APIå¯†é’¥ï¼š

```bash
# è®¾ç½®Gemini APIå¯†é’¥
export GEMINI_API_KEY="your-gemini-api-key"

# æˆ–è€…åœ¨Pythonä»£ç ä¸­è®¾ç½®
import os
os.environ['GEMINI_API_KEY'] = 'your-gemini-api-key'
```

### é¡¹ç›®é…ç½®æ–‡ä»¶

åˆ›å»ºä¸€ä¸ªé…ç½®æ–‡ä»¶ `aipm_config.py`ï¼š

```python
# aipm_config.py
from pathlib import Path

class AIPMConfig:
    # é¡¹ç›®è·¯å¾„é…ç½®
    PROJECT_ROOT = Path(".")
    PRDS_DIR = PROJECT_ROOT / "prds"
    EPICS_DIR = PROJECT_ROOT / "epics"
    FEATURES_DIR = PROJECT_ROOT / "features"
    
    # AIé…ç½®
    AI_MODEL = "gemini-2.5-pro"
    AI_API_KEY_ENV = "GEMINI_API_KEY"
    
    # æ–‡ä»¶æ¨¡æ¿é…ç½®
    PRD_TEMPLATE_PATH = None  # ä½¿ç”¨é»˜è®¤æ¨¡æ¿
    TASK_TEMPLATE_PATH = None  # ä½¿ç”¨é»˜è®¤æ¨¡æ¿
    
    # éªŒè¯è§„åˆ™
    REQUIRED_PRD_FIELDS = ['name', 'status', 'created', 'description']
    REQUIRED_TASK_FIELDS = ['name', 'status', 'created', 'epic']
    
    @classmethod
    def ensure_directories(cls):
        """ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„ç›®å½•å­˜åœ¨"""
        from aipm.core.base import BaseFileManager
        file_manager = BaseFileManager()
        
        for dir_path in [cls.PRDS_DIR, cls.EPICS_DIR, cls.FEATURES_DIR]:
            file_manager.ensure_directory(dir_path)
```

## åŸºç¡€ç”¨æ³•

### 1. æ•°æ®éªŒè¯

```python
from aipm.core.base import BaseValidator

validator = BaseValidator()

# éªŒè¯åŠŸèƒ½åç§°
feature_names = ['user-auth', 'UserAuth', 'user_auth', 'user-auth-system']
for name in feature_names:
    is_valid, message = validator.validate_feature_name(name)
    print(f"{name}: {'âœ…' if is_valid else 'âŒ'} {message}")

# éªŒè¯Frontmatter
content = """---
name: user-auth
status: draft
created: 2024-01-01 12:00:00 UTC
---

# User Authentication
å†…å®¹..."""

is_valid, message = validator.validate_frontmatter(
    content, 
    ['name', 'status', 'created']
)
print(f"FrontmatteréªŒè¯: {'âœ…' if is_valid else 'âŒ'} {message}")
```

### 2. æ–‡ä»¶æ“ä½œ

```python
from aipm.core.base import BaseFileManager
from pathlib import Path

file_manager = BaseFileManager()

# åˆ›å»ºç›®å½•ç»“æ„
dirs_to_create = [
    Path("prds"),
    Path("epics"),
    Path("features/user-auth/backend"),
    Path("features/user-auth/frontend"),
    Path("features/user-auth/docs")
]

for dir_path in dirs_to_create:
    if file_manager.ensure_directory(dir_path):
        print(f"âœ… ç›®å½•å·²åˆ›å»º: {dir_path}")
    else:
        print(f"âŒ ç›®å½•åˆ›å»ºå¤±è´¥: {dir_path}")

# æ–‡ä»¶æ“ä½œç¤ºä¾‹
test_file = Path("test.md")
test_content = "# æµ‹è¯•æ–‡æ¡£\n\nè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ã€‚"

# å†™å…¥æ–‡ä»¶
if file_manager.write_file(test_file, test_content):
    print(f"âœ… æ–‡ä»¶å·²å†™å…¥: {test_file}")

# æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
if file_manager.file_exists(test_file):
    # è¯»å–æ–‡ä»¶
    content = file_manager.read_file(test_file)
    print(f"ğŸ“„ æ–‡ä»¶å†…å®¹: {content[:50]}...")

# è·å–å½“å‰æ—¶é—´
current_time = file_manager.get_current_datetime()
print(f"ğŸ•’ å½“å‰æ—¶é—´: {current_time}")
```

### 3. å†…å®¹ç”Ÿæˆ

#### PRDç”Ÿæˆ

```python
from aipm.commands.prd_new import PRDContentGenerator
from aipm.core.base import BaseFileManager

def create_prd_example():
    generator = PRDContentGenerator()
    file_manager = BaseFileManager()
    
    # åŠŸèƒ½ä¿¡æ¯
    feature_name = "shopping-cart"
    answers = {
        'description': 'è´­ç‰©è½¦åŠŸèƒ½æ¨¡å—',
        'executive_summary': 'å®ç°ç”¨æˆ·è´­ç‰©è½¦çš„æ·»åŠ ã€åˆ é™¤ã€ä¿®æ”¹å’Œç»“ç®—åŠŸèƒ½',
        'problem_statement': 'ç”¨æˆ·éœ€è¦ä¸€ä¸ªæ–¹ä¾¿çš„è´­ç‰©è½¦æ¥ç®¡ç†è¦è´­ä¹°çš„å•†å“',
        'user_stories': [
            'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿå°†å•†å“æ·»åŠ åˆ°è´­ç‰©è½¦',
            'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿä¿®æ”¹è´­ç‰©è½¦ä¸­å•†å“çš„æ•°é‡',
            'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿä»è´­ç‰©è½¦ä¸­åˆ é™¤å•†å“',
            'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤ŸæŸ¥çœ‹è´­ç‰©è½¦æ€»ä»·',
            'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿè¿›è¡Œç»“ç®—'
        ],
        'functional_requirements': [
            'æ·»åŠ å•†å“åˆ°è´­ç‰©è½¦',
            'ä¿®æ”¹å•†å“æ•°é‡',
            'åˆ é™¤è´­ç‰©è½¦å•†å“',
            'è®¡ç®—æ€»ä»·',
            'è´­ç‰©è½¦æŒä¹…åŒ–',
            'ç»“ç®—æµç¨‹'
        ],
        'non_functional_requirements': [
            'è´­ç‰©è½¦æ“ä½œå“åº”æ—¶é—´<1ç§’',
            'æ”¯æŒç¦»çº¿è´­ç‰©è½¦',
            'è´­ç‰©è½¦æ•°æ®åŒæ­¥',
            'æ”¯æŒå¤§é‡å•†å“ï¼ˆ1000+ï¼‰'
        ]
    }
    
    # ç”Ÿæˆå†…å®¹
    created_time = file_manager.get_current_datetime()
    content = generator.generate_content(feature_name, answers, created_time)
    
    # ä¿å­˜æ–‡ä»¶
    prd_path = Path(f"prds/{feature_name}.md")
    file_manager.ensure_directory(prd_path.parent)
    file_manager.write_file(prd_path, content)
    
    print(f"âœ… PRDå·²åˆ›å»º: {prd_path}")
    return prd_path

# æ‰§è¡Œç¤ºä¾‹
prd_path = create_prd_example()
```

#### ä»»åŠ¡åˆ†è§£

```python
from aipm.commands.epic_decompose import TaskContentGenerator
from aipm.core.base import BaseFileManager

def create_task_decomposition_example():
    generator = TaskContentGenerator()
    file_manager = BaseFileManager()
    
    feature_name = "shopping-cart"
    
    # Epicä¿¡æ¯
    epic_info = {
        'name': feature_name,
        'description': 'è´­ç‰©è½¦åŠŸèƒ½çš„å®Œæ•´å®ç°',
        'objectives': [
            'æä¾›å®Œæ•´çš„è´­ç‰©è½¦åŠŸèƒ½',
            'ç¡®ä¿è‰¯å¥½çš„ç”¨æˆ·ä½“éªŒ',
            'ä¿è¯æ•°æ®ä¸€è‡´æ€§å’Œå®‰å…¨æ€§'
        ],
        'scope': 'åŒ…æ‹¬å‰ç«¯ç•Œé¢ã€åç«¯APIã€æ•°æ®å­˜å‚¨å’Œä¸šåŠ¡é€»è¾‘'
    }
    
    # ä»»åŠ¡åˆ—è¡¨
    tasks = [
        {
            'name': 'è®¾è®¡è´­ç‰©è½¦æ•°æ®æ¨¡å‹',
            'category': 'backend',
            'priority': 'high',
            'effort': '1å¤©',
            'description': 'è®¾è®¡è´­ç‰©è½¦è¡¨ç»“æ„ï¼ŒåŒ…æ‹¬ç”¨æˆ·å…³è”ã€å•†å“ä¿¡æ¯ã€æ•°é‡ç­‰',
            'acceptance_criteria': 'æ•°æ®æ¨¡å‹è®¾è®¡å®Œæˆï¼Œé€šè¿‡è¯„å®¡',
            'dependencies': 'æ— '
        },
        {
            'name': 'å®ç°è´­ç‰©è½¦API',
            'category': 'backend',
            'priority': 'high',
            'effort': '3å¤©',
            'description': 'å®ç°è´­ç‰©è½¦çš„CRUDæ“ä½œAPIï¼ŒåŒ…æ‹¬æ·»åŠ ã€åˆ é™¤ã€ä¿®æ”¹ã€æŸ¥è¯¢',
            'acceptance_criteria': 'APIåŠŸèƒ½å®Œæ•´ï¼Œé€šè¿‡å•å…ƒæµ‹è¯•',
            'dependencies': 'æ•°æ®æ¨¡å‹'
        },
        {
            'name': 'å¼€å‘è´­ç‰©è½¦å‰ç«¯ç»„ä»¶',
            'category': 'frontend',
            'priority': 'high',
            'effort': '4å¤©',
            'description': 'å¼€å‘è´­ç‰©è½¦ç•Œé¢ç»„ä»¶ï¼ŒåŒ…æ‹¬å•†å“åˆ—è¡¨ã€æ•°é‡æ§åˆ¶ã€æ€»ä»·è®¡ç®—',
            'acceptance_criteria': 'ç•Œé¢åŠŸèƒ½å®Œæ•´ï¼Œç”¨æˆ·ä½“éªŒè‰¯å¥½',
            'dependencies': 'è´­ç‰©è½¦API'
        },
        {
            'name': 'å®ç°è´­ç‰©è½¦çŠ¶æ€ç®¡ç†',
            'category': 'frontend',
            'priority': 'medium',
            'effort': '2å¤©',
            'description': 'å®ç°è´­ç‰©è½¦çš„å…¨å±€çŠ¶æ€ç®¡ç†ï¼ŒåŒ…æ‹¬æ•°æ®åŒæ­¥å’ŒæŒä¹…åŒ–',
            'acceptance_criteria': 'çŠ¶æ€ç®¡ç†æ­£ç¡®ï¼Œæ•°æ®åŒæ­¥æ­£å¸¸',
            'dependencies': 'å‰ç«¯ç»„ä»¶'
        },
        {
            'name': 'é›†æˆæµ‹è¯•',
            'category': 'testing',
            'priority': 'medium',
            'effort': '2å¤©',
            'description': 'è¿›è¡Œè´­ç‰©è½¦åŠŸèƒ½çš„ç«¯åˆ°ç«¯æµ‹è¯•',
            'acceptance_criteria': 'æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹é€šè¿‡',
            'dependencies': 'å‰åç«¯å¼€å‘å®Œæˆ'
        }
    ]
    
    # ç”Ÿæˆå†…å®¹
    created_time = file_manager.get_current_datetime()
    content = generator.generate_content(feature_name, epic_info, tasks, created_time)
    
    # ä¿å­˜æ–‡ä»¶
    tasks_path = Path(f"features/{feature_name}/tasks.md")
    file_manager.ensure_directory(tasks_path.parent)
    file_manager.write_file(tasks_path, content)
    
    print(f"âœ… ä»»åŠ¡åˆ†è§£å·²åˆ›å»º: {tasks_path}")
    print(f"ğŸ“Š æ€»ä»»åŠ¡æ•°: {len(tasks)}")
    
    # ç»Ÿè®¡ä»»åŠ¡ä¿¡æ¯
    categories = {}
    priorities = {}
    
    for task in tasks:
        cat = task['category']
        pri = task['priority']
        categories[cat] = categories.get(cat, 0) + 1
        priorities[pri] = priorities.get(pri, 0) + 1
    
    print("ğŸ“ˆ ä»»åŠ¡ç»Ÿè®¡:")
    print(f"   æŒ‰ç±»åˆ«: {dict(categories)}")
    print(f"   æŒ‰ä¼˜å…ˆçº§: {dict(priorities)}")
    
    return tasks_path

# æ‰§è¡Œç¤ºä¾‹
tasks_path = create_task_decomposition_example()
```

### 4. å†…å®¹æå–å’Œè§£æ

```python
from aipm.utils.helpers import ContentExtractor, ContentFormatter
from aipm.core.base import BaseFileManager

def content_extraction_example():
    file_manager = BaseFileManager()
    
    # å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªPRDæ–‡ä»¶
    prd_content = """---
name: user-auth
status: draft
created: 2024-01-01 12:00:00 UTC
description: ç”¨æˆ·è®¤è¯ç³»ç»Ÿ
---

# User Authentication System

## Executive Summary
è¿™æ˜¯ä¸€ä¸ªç”¨æˆ·è®¤è¯ç³»ç»Ÿçš„PRDæ–‡æ¡£ã€‚

## Problem Statement
å½“å‰ç³»ç»Ÿç¼ºä¹ç”¨æˆ·è®¤è¯æœºåˆ¶ã€‚

## User Stories
- ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿæ³¨å†Œè´¦æˆ·
- ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿå®‰å…¨ç™»å½•

## Functional Requirements
1. æ”¯æŒé‚®ç®±æ³¨å†Œ
2. æ”¯æŒå¯†ç ç™»å½•
3. æ”¯æŒå¯†ç é‡ç½®
"""
    
    # æå–Frontmatter
    frontmatter = ContentExtractor.extract_frontmatter(prd_content)
    print("ğŸ“‹ Frontmatterä¿¡æ¯:")
    for key, value in frontmatter.items():
        print(f"   {key}: {value}")
    
    # æå–ç‰¹å®šç« èŠ‚
    sections = ['Executive Summary', 'Problem Statement', 'User Stories']
    for section in sections:
        content = ContentExtractor.extract_section(prd_content, section)
        if content:
            print(f"\nğŸ“„ {section}:")
            print(f"   {content.strip()}")
    
    # æ ¼å¼åŒ–å†…å®¹
    user_stories = [
        'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿæ³¨å†Œè´¦æˆ·',
        'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿå®‰å…¨ç™»å½•',
        'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿé‡ç½®å¯†ç '
    ]
    
    formatted_list = ContentFormatter.format_list(user_stories, 'bullet')
    print(f"\nğŸ“ æ ¼å¼åŒ–çš„ç”¨æˆ·æ•…äº‹:")
    print(formatted_list)
    
    # æ ¼å¼åŒ–Frontmatter
    new_frontmatter = {
        'name': 'payment-system',
        'status': 'in-progress',
        'created': file_manager.get_current_datetime(),
        'description': 'æ”¯ä»˜ç³»ç»Ÿæ¨¡å—'
    }
    
    formatted_fm = ContentFormatter.format_frontmatter(new_frontmatter)
    print(f"\nğŸ“‹ æ ¼å¼åŒ–çš„Frontmatter:")
    print(formatted_fm)

# æ‰§è¡Œç¤ºä¾‹
content_extraction_example()
```

## é«˜çº§ç”¨æ³•

### 1. è‡ªå®šä¹‰å·¥ä½œæµæ­¥éª¤

```python
from aipm.core.base import BaseWorkflowStep
from aipm.core.base import BaseFileManager, ValidationError
from typing import Dict, Any
from pathlib import Path

class CustomPRDValidationStep(BaseWorkflowStep):
    """è‡ªå®šä¹‰PRDéªŒè¯æ­¥éª¤"""
    
    def __init__(self, feature_name: str, prd_path: Path):
        super().__init__(feature_name)
        self.prd_path = prd_path
        self.file_manager = BaseFileManager()
    
    def validate_preconditions(self) -> bool:
        """éªŒè¯PRDæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        if not self.file_manager.file_exists(self.prd_path):
            raise ValidationError(f"PRDæ–‡ä»¶ä¸å­˜åœ¨: {self.prd_path}")
        return True
    
    def execute(self) -> Dict[str, Any]:
        """æ‰§è¡ŒPRDéªŒè¯"""
        content = self.file_manager.read_file(self.prd_path)
        
        # éªŒè¯å¿…éœ€ç« èŠ‚
        required_sections = [
            'Executive Summary',
            'Problem Statement', 
            'User Stories',
            'Functional Requirements'
        ]
        
        missing_sections = []
        for section in required_sections:
            if f"## {section}" not in content:
                missing_sections.append(section)
        
        # éªŒè¯ç”¨æˆ·æ•…äº‹æ•°é‡
        user_stories_count = content.count('ä½œä¸ºç”¨æˆ·') + content.count('As a user')
        
        return {
            'prd_path': str(self.prd_path),
            'missing_sections': missing_sections,
            'user_stories_count': user_stories_count,
            'validation_passed': len(missing_sections) == 0 and user_stories_count >= 3
        }
    
    def post_process(self, result: Dict[str, Any]) -> bool:
        """åå¤„ç†éªŒè¯ç»“æœ"""
        if result['validation_passed']:
            print(f"âœ… PRDéªŒè¯é€šè¿‡: {result['prd_path']}")
            print(f"   ç”¨æˆ·æ•…äº‹æ•°é‡: {result['user_stories_count']}")
        else:
            print(f"âŒ PRDéªŒè¯å¤±è´¥: {result['prd_path']}")
            if result['missing_sections']:
                print(f"   ç¼ºå¤±ç« èŠ‚: {', '.join(result['missing_sections'])}")
            if result['user_stories_count'] < 3:
                print(f"   ç”¨æˆ·æ•…äº‹ä¸è¶³: {result['user_stories_count']} < 3")
        
        return result['validation_passed']

# ä½¿ç”¨è‡ªå®šä¹‰å·¥ä½œæµæ­¥éª¤
def run_custom_validation():
    feature_name = "user-auth"
    prd_path = Path(f"prds/{feature_name}.md")
    
    validation_step = CustomPRDValidationStep(feature_name, prd_path)
    
    try:
        result = validation_step.run()
        print(f"ğŸ¯ éªŒè¯ç»“æœ: {result}")
    except ValidationError as e:
        print(f"âŒ éªŒè¯é”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œé”™è¯¯: {e}")

# æ‰§è¡Œç¤ºä¾‹
# run_custom_validation()
```

### 2. AIé›†æˆç¤ºä¾‹

```python
from aipm.ai.client import AIClient, AIPromptBuilder
from aipm.commands.prd_new import PRDContentGenerator
from aipm.core.base import BaseFileManager
import os

def ai_assisted_prd_creation():
    """AIè¾…åŠ©PRDåˆ›å»ºç¤ºä¾‹"""
    
    # æ£€æŸ¥APIå¯†é’¥
    if not os.getenv('GEMINI_API_KEY'):
        print("âš ï¸  è¯·è®¾ç½®GEMINI_API_KEYç¯å¢ƒå˜é‡")
        return
    
    # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
    ai_client = AIClient()
    if not ai_client.configure():
        print("âŒ AIå®¢æˆ·ç«¯é…ç½®å¤±è´¥")
        return
    
    # åŸºç¡€åŠŸèƒ½ä¿¡æ¯
    feature_name = "notification-system"
    basic_info = {
        'name': feature_name,
        'description': 'ç³»ç»Ÿé€šçŸ¥åŠŸèƒ½æ¨¡å—'
    }
    
    # æ„å»ºAIæç¤º
    prompt = AIPromptBuilder.build_prd_prompt(feature_name, basic_info)
    print(f"ğŸ¤– AIæç¤º: {prompt[:200]}...")
    
    # ç”ŸæˆAIå†…å®¹
    print("ğŸ”„ æ­£åœ¨ç”ŸæˆAIå†…å®¹...")
    ai_response = ai_client.generate_content(prompt)
    
    if ai_response:
        print(f"âœ… AIç”ŸæˆæˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(ai_response)}")
        
        # è§£æAIå“åº”ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…AIå“åº”æ ¼å¼è¿›è¡Œè§£æï¼‰
        # ç®€åŒ–ç¤ºä¾‹ï¼Œå®é™…ä½¿ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„è§£æé€»è¾‘
        answers = {
            'description': 'ç³»ç»Ÿé€šçŸ¥åŠŸèƒ½æ¨¡å—',
            'executive_summary': 'AIç”Ÿæˆçš„æ‰§è¡Œæ‘˜è¦',
            'problem_statement': 'AIç”Ÿæˆçš„é—®é¢˜é™ˆè¿°',
            'user_stories': [
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿæ¥æ”¶ç³»ç»Ÿé€šçŸ¥',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿç®¡ç†é€šçŸ¥è®¾ç½®'
            ],
            'functional_requirements': [
                'å®æ—¶é€šçŸ¥æ¨é€',
                'é€šçŸ¥å†å²è®°å½•',
                'é€šçŸ¥è®¾ç½®ç®¡ç†'
            ],
            'non_functional_requirements': [
                'é€šçŸ¥å»¶è¿Ÿ<1ç§’',
                'æ”¯æŒ10ä¸‡å¹¶å‘ç”¨æˆ·',
                '99.9%å¯ç”¨æ€§'
            ]
        }
        
        # ç”Ÿæˆæœ€ç»ˆPRD
        generator = PRDContentGenerator()
        file_manager = BaseFileManager()
        
        created_time = file_manager.get_current_datetime()
        prd_content = generator.generate_content(feature_name, answers, created_time)
        
        # ä¿å­˜æ–‡ä»¶
        prd_path = Path(f"prds/{feature_name}.md")
        file_manager.ensure_directory(prd_path.parent)
        file_manager.write_file(prd_path, prd_content)
        
        print(f"âœ… AIè¾…åŠ©PRDå·²åˆ›å»º: {prd_path}")
    else:
        print("âŒ AIå†…å®¹ç”Ÿæˆå¤±è´¥")

# æ‰§è¡Œç¤ºä¾‹ï¼ˆéœ€è¦APIå¯†é’¥ï¼‰
# ai_assisted_prd_creation()
```

### 3. æ‰¹é‡å¤„ç†ç¤ºä¾‹

```python
from aipm.core.base import BaseFileManager, BaseValidator
from aipm.utils.helpers import ContentExtractor
from pathlib import Path
import json

def batch_process_prds():
    """æ‰¹é‡å¤„ç†PRDæ–‡ä»¶ç¤ºä¾‹"""
    
    file_manager = BaseFileManager()
    validator = BaseValidator()
    
    prds_dir = Path("prds")
    if not prds_dir.exists():
        print(f"âŒ PRDç›®å½•ä¸å­˜åœ¨: {prds_dir}")
        return
    
    # æ”¶é›†æ‰€æœ‰PRDæ–‡ä»¶
    prd_files = list(prds_dir.glob("*.md"))
    print(f"ğŸ“ æ‰¾åˆ° {len(prd_files)} ä¸ªPRDæ–‡ä»¶")
    
    results = []
    
    for prd_file in prd_files:
        print(f"\nğŸ” å¤„ç†æ–‡ä»¶: {prd_file.name}")
        
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            content = file_manager.read_file(prd_file)
            
            # æå–Frontmatter
            frontmatter = ContentExtractor.extract_frontmatter(content)
            
            # éªŒè¯Frontmatter
            is_valid, message = validator.validate_frontmatter(
                content, 
                ['name', 'status', 'created']
            )
            
            # ç»Ÿè®¡ä¿¡æ¯
            word_count = len(content.split())
            section_count = content.count('##')
            user_stories_count = content.count('ä½œä¸ºç”¨æˆ·') + content.count('As a user')
            
            result = {
                'file': prd_file.name,
                'frontmatter': frontmatter,
                'validation': {
                    'is_valid': is_valid,
                    'message': message
                },
                'statistics': {
                    'word_count': word_count,
                    'section_count': section_count,
                    'user_stories_count': user_stories_count
                }
            }
            
            results.append(result)
            
            # è¾“å‡ºç»“æœ
            status = "âœ…" if is_valid else "âŒ"
            print(f"   {status} éªŒè¯: {message or 'é€šè¿‡'}")
            print(f"   ğŸ“Š ç»Ÿè®¡: {word_count}è¯, {section_count}ç« èŠ‚, {user_stories_count}ç”¨æˆ·æ•…äº‹")
            
        except Exception as e:
            print(f"   âŒ å¤„ç†é”™è¯¯: {e}")
            results.append({
                'file': prd_file.name,
                'error': str(e)
            })
    
    # ç”ŸæˆæŠ¥å‘Š
    report_path = Path("prd_analysis_report.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“‹ åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    # æ±‡æ€»ç»Ÿè®¡
    valid_count = sum(1 for r in results if r.get('validation', {}).get('is_valid', False))
    total_words = sum(r.get('statistics', {}).get('word_count', 0) for r in results)
    total_stories = sum(r.get('statistics', {}).get('user_stories_count', 0) for r in results)
    
    print(f"\nğŸ“ˆ æ±‡æ€»ç»Ÿè®¡:")
    print(f"   æœ‰æ•ˆPRD: {valid_count}/{len(results)}")
    print(f"   æ€»å­—æ•°: {total_words}")
    print(f"   æ€»ç”¨æˆ·æ•…äº‹: {total_stories}")

# æ‰§è¡Œç¤ºä¾‹
# batch_process_prds()
```

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

```python
from aipm.core.base import ValidationError, FileOperationError
from aipm.core.base import BaseFileManager
from pathlib import Path

def robust_file_operations():
    """å¥å£®çš„æ–‡ä»¶æ“ä½œç¤ºä¾‹"""
    
    file_manager = BaseFileManager()
    
    try:
        # å°è¯•è¯»å–å¯èƒ½ä¸å­˜åœ¨çš„æ–‡ä»¶
        file_path = Path("non-existent-file.md")
        
        if file_manager.file_exists(file_path):
            content = file_manager.read_file(file_path)
            print(f"âœ… æ–‡ä»¶è¯»å–æˆåŠŸ: {len(content)}å­—ç¬¦")
        else:
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            # åˆ›å»ºé»˜è®¤å†…å®¹
            default_content = "# é»˜è®¤æ–‡æ¡£\n\nè¿™æ˜¯ä¸€ä¸ªé»˜è®¤åˆ›å»ºçš„æ–‡æ¡£ã€‚"
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            file_manager.ensure_directory(file_path.parent)
            
            # å†™å…¥æ–‡ä»¶
            if file_manager.write_file(file_path, default_content):
                print(f"âœ… é»˜è®¤æ–‡ä»¶å·²åˆ›å»º: {file_path}")
            else:
                print(f"âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥: {file_path}")
                
    except FileOperationError as e:
        print(f"âŒ æ–‡ä»¶æ“ä½œé”™è¯¯: {e}")
    except ValidationError as e:
        print(f"âŒ éªŒè¯é”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")

# æ‰§è¡Œç¤ºä¾‹
robust_file_operations()
```

### 2. é…ç½®ç®¡ç†

```python
from pathlib import Path
import json
from typing import Dict, Any

class ProjectConfig:
    """é¡¹ç›®é…ç½®ç®¡ç†"""
    
    def __init__(self, config_path: Path = Path("aipm_config.json")):
        self.config_path = config_path
        self.config = self._load_config()
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if self.config_path.exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "project": {
                "name": "My Project",
                "version": "1.0.0",
                "description": "é¡¹ç›®æè¿°"
            },
            "directories": {
                "prds": "prds",
                "epics": "epics",
                "features": "features",
                "docs": "docs"
            },
            "ai": {
                "model": "gemini-2.5-pro",
                "api_key_env": "GEMINI_API_KEY",
                "enabled": False
            },
            "validation": {
                "required_prd_fields": ["name", "status", "created", "description"],
                "required_task_fields": ["name", "status", "created", "epic"],
                "min_user_stories": 3
            },
            "templates": {
                "prd_template": None,
                "task_template": None
            }
        }
    
    def save_config(self):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        with open(self.config_path, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, ensure_ascii=False, indent=2)
    
    def get(self, key: str, default=None):
        """è·å–é…ç½®å€¼"""
        keys = key.split('.')
        value = self.config
        
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return default
        
        return value
    
    def set(self, key: str, value):
        """è®¾ç½®é…ç½®å€¼"""
        keys = key.split('.')
        config = self.config
        
        for k in keys[:-1]:
            if k not in config:
                config[k] = {}
            config = config[k]
        
        config[keys[-1]] = value

# ä½¿ç”¨é…ç½®ç®¡ç†
def config_management_example():
    config = ProjectConfig()
    
    # è·å–é…ç½®
    project_name = config.get('project.name', 'Unknown Project')
    prds_dir = config.get('directories.prds', 'prds')
    ai_enabled = config.get('ai.enabled', False)
    
    print(f"ğŸ“‹ é¡¹ç›®åç§°: {project_name}")
    print(f"ğŸ“ PRDç›®å½•: {prds_dir}")
    print(f"ğŸ¤– AIåŠŸèƒ½: {'å¯ç”¨' if ai_enabled else 'ç¦ç”¨'}")
    
    # ä¿®æ”¹é…ç½®
    config.set('ai.enabled', True)
    config.set('project.description', 'è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨AIPMçš„é¡¹ç›®')
    
    # ä¿å­˜é…ç½®
    config.save_config()
    print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {config.config_path}")

# æ‰§è¡Œç¤ºä¾‹
config_management_example()
```

### 3. æ—¥å¿—è®°å½•

```python
import logging
from pathlib import Path
from datetime import datetime

def setup_logging():
    """è®¾ç½®æ—¥å¿—è®°å½•"""
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    # é…ç½®æ–‡ä»¶æ—¥å¿—
    log_file = log_dir / f"aipm_{datetime.now().strftime('%Y%m%d')}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger('aipm')

def logging_example():
    """æ—¥å¿—è®°å½•ç¤ºä¾‹"""
    
    logger = setup_logging()
    
    logger.info("ğŸš€ AIPMåº”ç”¨å¯åŠ¨")
    
    try:
        # æ¨¡æ‹Ÿä¸€äº›æ“ä½œ
        logger.info("ğŸ“‹ å¼€å§‹åˆ›å»ºPRD")
        
        # æ¨¡æ‹ŸæˆåŠŸæ“ä½œ
        feature_name = "test-feature"
        logger.info(f"âœ… PRDåˆ›å»ºæˆåŠŸ: {feature_name}")
        
        # æ¨¡æ‹Ÿè­¦å‘Š
        logger.warning("âš ï¸  æ£€æµ‹åˆ°é‡å¤çš„åŠŸèƒ½åç§°")
        
        # æ¨¡æ‹Ÿé”™è¯¯
        try:
            raise ValueError("æµ‹è¯•é”™è¯¯")
        except ValueError as e:
            logger.error(f"âŒ æ“ä½œå¤±è´¥: {e}")
    
    except Exception as e:
        logger.critical(f"ğŸ’¥ ä¸¥é‡é”™è¯¯: {e}")
    
    finally:
        logger.info("ğŸ AIPMåº”ç”¨ç»“æŸ")

# æ‰§è¡Œç¤ºä¾‹
logging_example()
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æ¨¡å—å¯¼å…¥é”™è¯¯

```python
# é”™è¯¯ç¤ºä¾‹
try:
    from aipm.core.base import BaseValidator
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
    print("   1. ç¡®ä¿aipmåŒ…åœ¨Pythonè·¯å¾„ä¸­")
    print("   2. æ£€æŸ¥åŒ…ç»“æ„æ˜¯å¦å®Œæ•´")
    print("   3. ç¡®ä¿__init__.pyæ–‡ä»¶å­˜åœ¨")
```

#### 2. æ–‡ä»¶æƒé™é—®é¢˜

```python
from aipm.core.base import BaseFileManager, FileOperationError
from pathlib import Path

def handle_permission_issues():
    file_manager = BaseFileManager()
    
    try:
        # å°è¯•å†™å…¥å¯èƒ½æ²¡æœ‰æƒé™çš„ä½ç½®
        restricted_path = Path("/root/test.md")
        file_manager.write_file(restricted_path, "æµ‹è¯•å†…å®¹")
    
    except FileOperationError as e:
        print(f"âŒ æ–‡ä»¶æ“ä½œå¤±è´¥: {e}")
        print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("   1. æ£€æŸ¥æ–‡ä»¶/ç›®å½•æƒé™")
        print("   2. ä½¿ç”¨æœ‰æƒé™çš„ç›®å½•")
        print("   3. ä»¥é€‚å½“çš„ç”¨æˆ·èº«ä»½è¿è¡Œ")
        
        # ä½¿ç”¨æ›¿ä»£è·¯å¾„
        alternative_path = Path("./test.md")
        if file_manager.write_file(alternative_path, "æµ‹è¯•å†…å®¹"):
            print(f"âœ… ä½¿ç”¨æ›¿ä»£è·¯å¾„æˆåŠŸ: {alternative_path}")
```

#### 3. AI APIé…ç½®é—®é¢˜

```python
from aipm.ai.client import AIClient
import os

def diagnose_ai_issues():
    print("ğŸ” AIé…ç½®è¯Šæ–­:")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("âŒ GEMINI_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
        print("ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("   export GEMINI_API_KEY='your-api-key'")
        return
    
    print(f"âœ… APIå¯†é’¥å·²è®¾ç½® (é•¿åº¦: {len(api_key)})")
    
    # æµ‹è¯•AIå®¢æˆ·ç«¯
    client = AIClient()
    if client.configure():
        print("âœ… AIå®¢æˆ·ç«¯é…ç½®æˆåŠŸ")
        
        # æµ‹è¯•ç®€å•è¯·æ±‚
        try:
            response = client.generate_content("Hello, AI!")
            if response:
                print(f"âœ… AIå“åº”æµ‹è¯•æˆåŠŸ (é•¿åº¦: {len(response)})")
            else:
                print("âŒ AIå“åº”ä¸ºç©º")
        except Exception as e:
            print(f"âŒ AIè¯·æ±‚å¤±è´¥: {e}")
    else:
        print("âŒ AIå®¢æˆ·ç«¯é…ç½®å¤±è´¥")

# æ‰§è¡Œè¯Šæ–­
# diagnose_ai_issues()
```

## ç¤ºä¾‹é¡¹ç›®

### å®Œæ•´çš„ç”µå•†é¡¹ç›®ç¤ºä¾‹

```python
from aipm.commands.prd_new import PRDContentGenerator
from aipm.commands.epic_decompose import TaskContentGenerator
from aipm.core.base import BaseFileManager
from pathlib import Path

def create_ecommerce_project():
    """åˆ›å»ºå®Œæ•´çš„ç”µå•†é¡¹ç›®ç¤ºä¾‹"""
    
    file_manager = BaseFileManager()
    prd_generator = PRDContentGenerator()
    task_generator = TaskContentGenerator()
    
    # ç”µå•†åŠŸèƒ½åˆ—è¡¨
    features = {
        'user-management': {
            'description': 'ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ',
            'user_stories': [
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿæ³¨å†Œè´¦æˆ·',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿç™»å½•ç³»ç»Ÿ',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿç®¡ç†ä¸ªäººèµ„æ–™',
                'ä½œä¸ºç®¡ç†å‘˜ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿç®¡ç†ç”¨æˆ·è´¦æˆ·'
            ],
            'tasks': [
                {'name': 'ç”¨æˆ·æ³¨å†ŒAPI', 'category': 'backend', 'priority': 'high', 'effort': '3å¤©'},
                {'name': 'ç”¨æˆ·ç™»å½•API', 'category': 'backend', 'priority': 'high', 'effort': '2å¤©'},
                {'name': 'ç”¨æˆ·ç®¡ç†ç•Œé¢', 'category': 'frontend', 'priority': 'medium', 'effort': '4å¤©'}
            ]
        },
        'product-catalog': {
            'description': 'å•†å“ç›®å½•ç³»ç»Ÿ',
            'user_stories': [
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿæµè§ˆå•†å“',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿæœç´¢å•†å“',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤ŸæŸ¥çœ‹å•†å“è¯¦æƒ…',
                'ä½œä¸ºç®¡ç†å‘˜ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿç®¡ç†å•†å“ä¿¡æ¯'
            ],
            'tasks': [
                {'name': 'å•†å“æ•°æ®æ¨¡å‹', 'category': 'backend', 'priority': 'high', 'effort': '2å¤©'},
                {'name': 'å•†å“API', 'category': 'backend', 'priority': 'high', 'effort': '4å¤©'},
                {'name': 'å•†å“åˆ—è¡¨é¡µé¢', 'category': 'frontend', 'priority': 'high', 'effort': '3å¤©'},
                {'name': 'å•†å“è¯¦æƒ…é¡µé¢', 'category': 'frontend', 'priority': 'medium', 'effort': '3å¤©'}
            ]
        },
        'shopping-cart': {
            'description': 'è´­ç‰©è½¦ç³»ç»Ÿ',
            'user_stories': [
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿæ·»åŠ å•†å“åˆ°è´­ç‰©è½¦',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿä¿®æ”¹è´­ç‰©è½¦å•†å“æ•°é‡',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿåˆ é™¤è´­ç‰©è½¦å•†å“',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤ŸæŸ¥çœ‹è´­ç‰©è½¦æ€»ä»·'
            ],
            'tasks': [
                {'name': 'è´­ç‰©è½¦æ•°æ®æ¨¡å‹', 'category': 'backend', 'priority': 'high', 'effort': '1å¤©'},
                {'name': 'è´­ç‰©è½¦API', 'category': 'backend', 'priority': 'high', 'effort': '3å¤©'},
                {'name': 'è´­ç‰©è½¦ç»„ä»¶', 'category': 'frontend', 'priority': 'high', 'effort': '4å¤©'}
            ]
        },
        'order-management': {
            'description': 'è®¢å•ç®¡ç†ç³»ç»Ÿ',
            'user_stories': [
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿåˆ›å»ºè®¢å•',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤ŸæŸ¥çœ‹è®¢å•çŠ¶æ€',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿå–æ¶ˆè®¢å•',
                'ä½œä¸ºç®¡ç†å‘˜ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿå¤„ç†è®¢å•'
            ],
            'tasks': [
                {'name': 'è®¢å•æ•°æ®æ¨¡å‹', 'category': 'backend', 'priority': 'high', 'effort': '2å¤©'},
                {'name': 'è®¢å•API', 'category': 'backend', 'priority': 'high', 'effort': '5å¤©'},
                {'name': 'è®¢å•ç®¡ç†ç•Œé¢', 'category': 'frontend', 'priority': 'medium', 'effort': '4å¤©'}
            ]
        },
        'payment-system': {
            'description': 'æ”¯ä»˜ç³»ç»Ÿ',
            'user_stories': [
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿé€‰æ‹©æ”¯ä»˜æ–¹å¼',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿå®‰å…¨åœ°å®Œæˆæ”¯ä»˜',
                'ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘å¸Œæœ›èƒ½å¤ŸæŸ¥çœ‹æ”¯ä»˜è®°å½•',
                'ä½œä¸ºç³»ç»Ÿï¼Œæˆ‘å¸Œæœ›èƒ½å¤Ÿå¤„ç†æ”¯ä»˜å›è°ƒ'
            ],
            'tasks': [
                {'name': 'æ”¯ä»˜æ¥å£é›†æˆ', 'category': 'backend', 'priority': 'high', 'effort': '4å¤©'},
                {'name': 'æ”¯ä»˜å®‰å…¨éªŒè¯', 'category': 'backend', 'priority': 'high', 'effort': '3å¤©'},
                {'name': 'æ”¯ä»˜ç•Œé¢', 'category': 'frontend', 'priority': 'high', 'effort': '3å¤©'}
            ]
        }
    }
    
    print("ğŸš€ å¼€å§‹åˆ›å»ºç”µå•†é¡¹ç›®æ–‡æ¡£...")
    
    created_time = file_manager.get_current_datetime()
    
    for feature_name, feature_info in features.items():
        print(f"\nğŸ“‹ åˆ›å»ºåŠŸèƒ½: {feature_name}")
        
        # åˆ›å»ºPRD
        prd_answers = {
            'description': feature_info['description'],
            'executive_summary': f"{feature_info['description']}çš„å®Œæ•´å®ç°",
            'problem_statement': f"ç³»ç»Ÿéœ€è¦{feature_info['description']}æ¥æ”¯æŒä¸šåŠ¡éœ€æ±‚",
            'user_stories': feature_info['user_stories'],
            'functional_requirements': [f"å®ç°{story.split('ï¼Œ')[1]}" for story in feature_info['user_stories']],
            'non_functional_requirements': [
                'å“åº”æ—¶é—´<2ç§’',
                'æ”¯æŒé«˜å¹¶å‘',
                'æ•°æ®å®‰å…¨æ€§'
            ]
        }
        
        prd_content = prd_generator.generate_content(feature_name, prd_answers, created_time)
        prd_path = Path(f"prds/{feature_name}.md")
        file_manager.ensure_directory(prd_path.parent)
        file_manager.write_file(prd_path, prd_content)
        print(f"   âœ… PRDå·²åˆ›å»º: {prd_path}")
        
        # åˆ›å»ºä»»åŠ¡åˆ†è§£
        epic_info = {
            'name': feature_name,
            'description': feature_info['description'],
            'objectives': [f"å®ç°{feature_info['description']}çš„æ ¸å¿ƒåŠŸèƒ½"]
        }
        
        # æ‰©å±•ä»»åŠ¡ä¿¡æ¯
        detailed_tasks = []
        for task in feature_info['tasks']:
            detailed_task = {
                'name': task['name'],
                'category': task['category'],
                'priority': task['priority'],
                'effort': task['effort'],
                'description': f"å®ç°{task['name']}çš„å®Œæ•´åŠŸèƒ½",
                'acceptance_criteria': f"{task['name']}åŠŸèƒ½å®Œæ•´å¹¶é€šè¿‡æµ‹è¯•",
                'dependencies': 'å‰ç½®ä»»åŠ¡å®Œæˆ'
            }
            detailed_tasks.append(detailed_task)
        
        task_content = task_generator.generate_content(feature_name, epic_info, detailed_tasks, created_time)
        task_path = Path(f"features/{feature_name}/tasks.md")
        file_manager.ensure_directory(task_path.parent)
        file_manager.write_file(task_path, task_content)
        print(f"   âœ… ä»»åŠ¡åˆ†è§£å·²åˆ›å»º: {task_path}")
        print(f"   ğŸ“Š ä»»åŠ¡æ•°é‡: {len(detailed_tasks)}")
    
    # åˆ›å»ºé¡¹ç›®æ€»è§ˆ
    project_overview = f"""# ç”µå•†é¡¹ç›®æ€»è§ˆ

åˆ›å»ºæ—¶é—´: {created_time}

## é¡¹ç›®åŠŸèƒ½æ¨¡å—

{chr(10).join([f"- **{name}**: {info['description']}" for name, info in features.items()])}

## ç»Ÿè®¡ä¿¡æ¯

- åŠŸèƒ½æ¨¡å—æ•°: {len(features)}
- æ€»ä»»åŠ¡æ•°: {sum(len(info['tasks']) for info in features.values())}
- æ€»ç”¨æˆ·æ•…äº‹æ•°: {sum(len(info['user_stories']) for info in features.values())}

## é¡¹ç›®ç»“æ„

```txt

ecommerce-project/
â”œâ”€â”€ prds/                 # PRDæ–‡æ¡£
{chr(10).join([f"â”‚   â”œâ”€â”€ {name}.md" for name in features.keys()])}
â”œâ”€â”€ features/             # åŠŸèƒ½å¼€å‘
{chr(10).join([f"â”‚   â”œâ”€â”€ {name}/" for name in features.keys()])}
{chr(10).join([f"â”‚   â”‚   â””â”€â”€ tasks.md" for _ in features.keys()])}
â””â”€â”€ docs/                 # é¡¹ç›®æ–‡æ¡£
    â””â”€â”€ project-overview.md

```

## å¼€å‘å»ºè®®

1. **å¼€å‘é¡ºåº**: å»ºè®®æŒ‰ç…§ç”¨æˆ·ç®¡ç† â†’ å•†å“ç›®å½• â†’ è´­ç‰©è½¦ â†’ è®¢å•ç®¡ç† â†’ æ”¯ä»˜ç³»ç»Ÿçš„é¡ºåºè¿›è¡Œå¼€å‘
2. **æŠ€æœ¯æ ˆ**: å»ºè®®ä½¿ç”¨ç°ä»£åŒ–çš„æŠ€æœ¯æ ˆï¼Œå¦‚React/Vue + Node.js/Python + MySQL/PostgreSQL
3. **æµ‹è¯•ç­–ç•¥**: æ¯ä¸ªæ¨¡å—éƒ½åº”è¯¥åŒ…å«å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•å’Œç«¯åˆ°ç«¯æµ‹è¯•
4. **éƒ¨ç½²æ–¹æ¡ˆ**: å»ºè®®ä½¿ç”¨å®¹å™¨åŒ–éƒ¨ç½²ï¼Œæ”¯æŒCI/CDæµç¨‹

## é‡Œç¨‹ç¢‘

- **é˜¶æ®µ1**: ç”¨æˆ·ç®¡ç†å’Œå•†å“ç›®å½• (é¢„è®¡4å‘¨)
- **é˜¶æ®µ2**: è´­ç‰©è½¦å’Œè®¢å•ç®¡ç† (é¢„è®¡3å‘¨)
- **é˜¶æ®µ3**: æ”¯ä»˜ç³»ç»Ÿå’Œä¼˜åŒ– (é¢„è®¡3å‘¨)
- **é˜¶æ®µ4**: æµ‹è¯•å’Œéƒ¨ç½² (é¢„è®¡2å‘¨)

æ€»é¢„è®¡å¼€å‘æ—¶é—´: 12å‘¨
"""

    overview_path = Path("docs/project-overview.md")
    file_manager.ensure_directory(overview_path.parent)
    file_manager.write_file(overview_path, project_overview)
    
    print(f"\nğŸ‰ ç”µå•†é¡¹ç›®æ–‡æ¡£åˆ›å»ºå®Œæˆ!")
    print(f"ğŸ“‹ æ€»åŠŸèƒ½æ•°: {len(features)}")
    print(f"ğŸ“„ æ€»æ–‡æ¡£æ•°: {len(features) * 2 + 1}")
    print(f"ğŸ“Š é¡¹ç›®æ€»è§ˆ: {overview_path}")

# æ‰§è¡Œå®Œæ•´é¡¹ç›®åˆ›å»º

# create_ecommerce_project()

```

è¿™ä¸ªä½¿ç”¨æŒ‡å—æä¾›äº†ä»åŸºç¡€ç”¨æ³•åˆ°é«˜çº§åŠŸèƒ½çš„å®Œæ•´ç¤ºä¾‹ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€ŸæŒæ¡AIPMåŒ…çš„ä½¿ç”¨æ–¹æ³•ã€‚é€šè¿‡è¿™äº›ç¤ºä¾‹ï¼Œç”¨æˆ·å¯ä»¥äº†è§£å¦‚ä½•åœ¨å®é™…é¡¹ç›®ä¸­åº”ç”¨AIPMçš„å„ç§åŠŸèƒ½ã€‚
