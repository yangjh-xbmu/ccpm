#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PRD Parse - å°†PRDè½¬æ¢ä¸ºæŠ€æœ¯å®ç°epic

è¿™ä¸ªè„šæœ¬å®ç°äº†ccpmçš„prd-parseåŠŸèƒ½ï¼Œå°†äº§å“éœ€æ±‚æ–‡æ¡£(PRD)è½¬æ¢ä¸ºè¯¦ç»†çš„æŠ€æœ¯å®ç°epicã€‚
æ”¯æŒäº¤äº’å¼ã€éäº¤äº’å¼å’ŒAIåä½œä¸‰ç§æ¨¡å¼ã€‚

ä½¿ç”¨æ–¹æ³•:
    python prd_parse.py <feature_name> [--non-interactive] [--ai]

ç¤ºä¾‹:
    python prd_parse.py user-auth
    python prd_parse.py payment-system --ai
    python prd_parse.py notification-service --non-interactive
"""

import os
import sys
import argparse
import subprocess
import re
from pathlib import Path

# å°è¯•å¯¼å…¥dotenvä»¥æ”¯æŒ.envæ–‡ä»¶
try:
    from dotenv import load_dotenv
    if not load_dotenv():
        print("è­¦å‘Šï¼šæœªæ‰¾åˆ°.envæ–‡ä»¶ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡")
except ImportError:
    pass  # å¦‚æœæ²¡æœ‰å®‰è£…python-dotenvï¼Œç»§ç»­ä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡

# AIé…ç½®
AI_API_KEY_ENV = "GEMINI_API_KEY"
AI_MODEL = "gemini-1.5-pro"

def validate_feature_name(feature_name):
    """éªŒè¯åŠŸèƒ½åç§°æ ¼å¼"""
    if not feature_name:
        return False, "åŠŸèƒ½åç§°ä¸èƒ½ä¸ºç©º"
    
    # æ£€æŸ¥æ ¼å¼ï¼šåªå…è®¸å°å†™å­—æ¯ã€æ•°å­—å’Œè¿å­—ç¬¦ï¼Œå¿…é¡»ä»¥å­—æ¯å¼€å¤´
    if not re.match(r'^[a-z][a-z0-9-]*$', feature_name):
        return False, "âŒ åŠŸèƒ½åç§°å¿…é¡»æ˜¯kebab-caseæ ¼å¼ï¼ˆå°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦ï¼‰ï¼Œä¾‹å¦‚ï¼šuser-auth, payment-v2, notification-system"
    
    return True, ""

def check_prd_exists(feature_name):
    """æ£€æŸ¥PRDæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    prd_file = Path(f".claude/prds/{feature_name}.md")
    return prd_file.exists(), prd_file

def validate_prd_frontmatter(prd_file):
    """éªŒè¯PRDæ–‡ä»¶çš„frontmatter"""
    try:
        with open(prd_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰frontmatter
        if not content.startswith('---'):
            return False, "PRDæ–‡ä»¶ç¼ºå°‘frontmatter"
        
        # æå–frontmatter
        parts = content.split('---', 2)
        if len(parts) < 3:
            return False, "PRDæ–‡ä»¶frontmatteræ ¼å¼é”™è¯¯"
        
        frontmatter = parts[1]
        required_fields = ['name:', 'description:', 'status:', 'created:']
        missing_fields = []
        
        for field in required_fields:
            if field not in frontmatter:
                missing_fields.append(field.rstrip(':'))
        
        if missing_fields:
            return False, f"PRD frontmatterç¼ºå°‘å¿…éœ€å­—æ®µï¼š{', '.join(missing_fields)}"
        
        return True, content
    
    except Exception as e:
        return False, f"è¯»å–PRDæ–‡ä»¶å¤±è´¥ï¼š{str(e)}"

def check_epic_exists(feature_name):
    """æ£€æŸ¥epicæ˜¯å¦å·²å­˜åœ¨"""
    epic_dir = Path(f".claude/epics/{feature_name}")
    epic_file = epic_dir / "epic.md"
    return epic_file.exists(), epic_file

def ensure_epic_directory(feature_name):
    """ç¡®ä¿epicç›®å½•å­˜åœ¨"""
    epic_dir = Path(f".claude/epics/{feature_name}")
    try:
        epic_dir.mkdir(parents=True, exist_ok=True)
        return True, epic_dir
    except Exception as e:
        return False, f"âŒ æ— æ³•åˆ›å»ºepicç›®å½•ï¼š{str(e)}"

def get_current_datetime():
    """è·å–å½“å‰ISOæ ¼å¼çš„æ—¥æœŸæ—¶é—´"""
    try:
        result = subprocess.run(['date', '-u', '+%Y-%m-%dT%H:%M:%SZ'], 
                              capture_output=True, text=True, check=True)
        return result.stdout.strip()
    except subprocess.CalledProcessError:
        # å¦‚æœç³»ç»Ÿå‘½ä»¤å¤±è´¥ï¼Œä½¿ç”¨Pythonçš„datetimeä½œä¸ºå¤‡é€‰
        from datetime import datetime
        return datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')

def extract_prd_info(prd_content):
    """ä»PRDå†…å®¹ä¸­æå–å…³é”®ä¿¡æ¯"""
    lines = prd_content.split('\n')
    
    # æå–frontmatterä¸­çš„æè¿°
    description = ""
    in_frontmatter = False
    
    for line in lines:
        if line.strip() == '---':
            if not in_frontmatter:
                in_frontmatter = True
            else:
                break
        elif in_frontmatter and line.startswith('description:'):
            description = line.split('description:', 1)[1].strip()
    
    # æå–ä¸»è¦ç« èŠ‚å†…å®¹
    sections = {
        'executive_summary': '',
        'problem_statement': '',
        'functional_requirements': '',
        'non_functional_requirements': '',
        'dependencies': ''
    }
    
    current_section = None
    content_lines = []
    
    for line in lines:
        if line.startswith('## Executive Summary'):
            current_section = 'executive_summary'
            content_lines = []
        elif line.startswith('## Problem Statement'):
            if current_section:
                sections[current_section] = '\n'.join(content_lines)
            current_section = 'problem_statement'
            content_lines = []
        elif line.startswith('### Functional Requirements'):
            if current_section:
                sections[current_section] = '\n'.join(content_lines)
            current_section = 'functional_requirements'
            content_lines = []
        elif line.startswith('### Non-Functional Requirements'):
            if current_section:
                sections[current_section] = '\n'.join(content_lines)
            current_section = 'non_functional_requirements'
            content_lines = []
        elif line.startswith('## Dependencies'):
            if current_section:
                sections[current_section] = '\n'.join(content_lines)
            current_section = 'dependencies'
            content_lines = []
        elif line.startswith('##') and current_section:
            # æ–°çš„ç« èŠ‚å¼€å§‹ï¼Œä¿å­˜å½“å‰ç« èŠ‚
            sections[current_section] = '\n'.join(content_lines)
            current_section = None
            content_lines = []
        elif current_section and line.strip():
            content_lines.append(line)
    
    # ä¿å­˜æœ€åä¸€ä¸ªç« èŠ‚
    if current_section and content_lines:
        sections[current_section] = '\n'.join(content_lines)
    
    return description, sections

def conduct_technical_analysis(feature_name, prd_info, mode='interactive'):
    """è¿›è¡ŒæŠ€æœ¯åˆ†æä¼šè¯"""
    if mode == 'non-interactive':
        return create_default_technical_analysis(feature_name, prd_info)
    
    print(f"\nğŸ”§ å¼€å§‹ä¸ºåŠŸèƒ½ '{feature_name}' è¿›è¡ŒæŠ€æœ¯åˆ†æ")
    print("\næˆ‘æ˜¯æŠ€æœ¯è´Ÿè´£äººï¼Œå°†åˆ†æPRDå¹¶åˆ¶å®šæŠ€æœ¯å®ç°æ–¹æ¡ˆã€‚")
    print("è®©æˆ‘ä»¬ä¸€èµ·åˆ†ææŠ€æœ¯æ¶æ„å’Œå®ç°ç­–ç•¥...\n")
    
    analysis = {}
    
    # ç¬¬ä¸€é˜¶æ®µï¼šæ¶æ„å†³ç­–
    print("=== ç¬¬ä¸€é˜¶æ®µï¼šæ¶æ„å†³ç­– ===")
    analysis['architecture_decisions'] = input("å…³é”®æŠ€æœ¯å†³ç­–å’Œç†ç”±ï¼ˆæŠ€æœ¯é€‰å‹ã€è®¾è®¡æ¨¡å¼ç­‰ï¼‰ï¼š")
    analysis['technology_stack'] = input("æŠ€æœ¯æ ˆé€‰æ‹©ï¼ˆå‰ç«¯ã€åç«¯ã€æ•°æ®åº“ç­‰ï¼‰ï¼š")
    
    # ç¬¬äºŒé˜¶æ®µï¼šæŠ€æœ¯æ–¹æ¡ˆ
    print("\n=== ç¬¬äºŒé˜¶æ®µï¼šæŠ€æœ¯å®ç°æ–¹æ¡ˆ ===")
    analysis['frontend_components'] = input("å‰ç«¯ç»„ä»¶éœ€æ±‚ï¼ˆUIç»„ä»¶ã€çŠ¶æ€ç®¡ç†ã€äº¤äº’æ¨¡å¼ï¼‰ï¼š")
    analysis['backend_services'] = input("åç«¯æœåŠ¡éœ€æ±‚ï¼ˆAPIç«¯ç‚¹ã€æ•°æ®æ¨¡å‹ã€ä¸šåŠ¡é€»è¾‘ï¼‰ï¼š")
    analysis['infrastructure'] = input("åŸºç¡€è®¾æ–½è€ƒè™‘ï¼ˆéƒ¨ç½²ã€æ‰©å±•ã€ç›‘æ§ï¼‰ï¼š")
    
    # ç¬¬ä¸‰é˜¶æ®µï¼šå®ç°ç­–ç•¥
    print("\n=== ç¬¬ä¸‰é˜¶æ®µï¼šå®ç°ç­–ç•¥ ===")
    analysis['implementation_phases'] = input("å¼€å‘é˜¶æ®µåˆ’åˆ†ï¼š")
    analysis['risk_mitigation'] = input("é£é™©ç¼“è§£ç­–ç•¥ï¼š")
    analysis['testing_approach'] = input("æµ‹è¯•æ–¹æ³•ï¼š")
    
    # ç¬¬å››é˜¶æ®µï¼šä»»åŠ¡åˆ†è§£é¢„è§ˆ
    print("\n=== ç¬¬å››é˜¶æ®µï¼šä»»åŠ¡åˆ†è§£é¢„è§ˆ ===")
    analysis['task_categories'] = input("é«˜çº§ä»»åŠ¡ç±»åˆ«ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰ï¼š")
    
    # ç¬¬äº”é˜¶æ®µï¼šå·¥ä½œé‡è¯„ä¼°
    print("\n=== ç¬¬äº”é˜¶æ®µï¼šå·¥ä½œé‡è¯„ä¼° ===")
    analysis['timeline_estimate'] = input("æ•´ä½“æ—¶é—´çº¿è¯„ä¼°ï¼š")
    analysis['resource_requirements'] = input("èµ„æºéœ€æ±‚ï¼š")
    analysis['critical_path'] = input("å…³é”®è·¯å¾„é¡¹ç›®ï¼š")
    
    print("\nâœ… æŠ€æœ¯åˆ†æå®Œæˆï¼æ­£åœ¨ç”Ÿæˆepicå†…å®¹...")
    return analysis

def create_default_technical_analysis(feature_name, prd_info):
    """ä¸ºéäº¤äº’æ¨¡å¼åˆ›å»ºé»˜è®¤æŠ€æœ¯åˆ†æ"""
    return {
        'architecture_decisions': 'å¾…æŠ€æœ¯å›¢é˜Ÿç¡®å®šæ¶æ„å†³ç­–å’ŒæŠ€æœ¯é€‰å‹',
        'technology_stack': 'å¾…è¯„ä¼°æŠ€æœ¯æ ˆé€‰æ‹©',
        'frontend_components': 'å¾…è®¾è®¡å‰ç«¯ç»„ä»¶æ¶æ„',
        'backend_services': 'å¾…è®¾è®¡åç«¯æœåŠ¡æ¶æ„',
        'infrastructure': 'å¾…è¯„ä¼°åŸºç¡€è®¾æ–½éœ€æ±‚',
        'implementation_phases': 'å¾…åˆ¶å®šå¼€å‘é˜¶æ®µè®¡åˆ’',
        'risk_mitigation': 'å¾…è¯†åˆ«å’Œç¼“è§£æŠ€æœ¯é£é™©',
        'testing_approach': 'å¾…åˆ¶å®šæµ‹è¯•ç­–ç•¥',
        'task_categories': 'è®¾è®¡, å¼€å‘, æµ‹è¯•, éƒ¨ç½²',
        'timeline_estimate': 'å¾…è¯„ä¼°å¼€å‘æ—¶é—´çº¿',
        'resource_requirements': 'å¾…è¯„ä¼°èµ„æºéœ€æ±‚',
        'critical_path': 'å¾…è¯†åˆ«å…³é”®è·¯å¾„'
    }

def create_epic_content(feature_name, prd_description, analysis, created_time):
    """åˆ›å»ºepicå†…å®¹"""
    
    # å¤„ç†ä»»åŠ¡ç±»åˆ«
    task_categories = analysis['task_categories'].split(',')
    task_breakdown = '\n'.join([f"- [ ] {cat.strip()}: å¾…è¯¦ç»†åˆ†è§£" for cat in task_categories if cat.strip()])
    
    content = f"""---
name: {feature_name}
status: backlog
created: {created_time}
progress: 0%
prd: .claude/prds/{feature_name}.md
github: [Will be updated when synced to GitHub]
---

# Epic: {feature_name}

## Overview
{prd_description}

## Architecture Decisions
{analysis['architecture_decisions']}

**æŠ€æœ¯æ ˆé€‰æ‹©ï¼š**
{analysis['technology_stack']}

## Technical Approach

### Frontend Components
{analysis['frontend_components']}

### Backend Services
{analysis['backend_services']}

### Infrastructure
{analysis['infrastructure']}

## Implementation Strategy

**å¼€å‘é˜¶æ®µï¼š**
{analysis['implementation_phases']}

**é£é™©ç¼“è§£ï¼š**
{analysis['risk_mitigation']}

**æµ‹è¯•æ–¹æ³•ï¼š**
{analysis['testing_approach']}

## Task Breakdown Preview
é«˜çº§ä»»åŠ¡ç±»åˆ«ï¼š
{task_breakdown}

## Dependencies
å¾…æŠ€æœ¯è¯„ä¼°ç¡®å®šå…·ä½“ä¾èµ–å…³ç³»

## Success Criteria (Technical)
- æ‰€æœ‰åŠŸèƒ½éœ€æ±‚å¾—åˆ°æŠ€æœ¯å®ç°
- æ€§èƒ½æŒ‡æ ‡è¾¾åˆ°PRDè¦æ±‚
- ä»£ç è´¨é‡ç¬¦åˆå›¢é˜Ÿæ ‡å‡†
- æµ‹è¯•è¦†ç›–ç‡è¾¾åˆ°è¦æ±‚

## Estimated Effort

**æ•´ä½“æ—¶é—´çº¿ï¼š**
{analysis['timeline_estimate']}

**èµ„æºéœ€æ±‚ï¼š**
{analysis['resource_requirements']}

**å…³é”®è·¯å¾„ï¼š**
{analysis['critical_path']}
"""
    
    return content

def save_epic(epic_file, content):
    """ä¿å­˜epicæ–‡ä»¶"""
    try:
        with open(epic_file, 'w', encoding='utf-8') as f:
            f.write(content)
        return True, ""
    except Exception as e:
        return False, f"âŒ ä¿å­˜epicæ–‡ä»¶å¤±è´¥ï¼š{str(e)}"

def show_epic_creation_summary(feature_name, analysis, created_time, epic_file):
    """æ˜¾ç¤ºepicåˆ›å»ºåçš„æ‘˜è¦"""
    task_count = len([cat.strip() for cat in analysis['task_categories'].split(',') if cat.strip()])
    
    print(f"\nâœ… Epicå·²åˆ›å»ºï¼š{epic_file}")
    print("\nğŸ“‹ Epicæ¦‚è¦ï¼š")
    print(f"- åŠŸèƒ½åç§°ï¼š{feature_name}")
    print(f"- çŠ¶æ€ï¼šbacklog")
    print(f"- åˆ›å»ºæ—¶é—´ï¼š{created_time}")
    print(f"- è¿›åº¦ï¼š0%")
    
    print("\nğŸ¯ æŠ€æœ¯åˆ†æç»“æœï¼š")
    print(f"- ä»»åŠ¡ç±»åˆ«æ•°é‡ï¼š{task_count}")
    print(f"- æ¶æ„å†³ç­–ï¼š{analysis['architecture_decisions'][:50]}...")
    print(f"- æ—¶é—´çº¿è¯„ä¼°ï¼š{analysis['timeline_estimate']}")
    
    print(f"\nğŸš€ å‡†å¤‡åˆ†è§£ä¸ºå…·ä½“ä»»åŠ¡ï¼Ÿè¿è¡Œï¼špython epic_decompose.py {feature_name}")
    print("\nğŸ’¡ æç¤ºï¼šä½¿ç”¨ /pm:epic-edit å¯ä»¥è¿›ä¸€æ­¥å®Œå–„Epicå†…å®¹")

def configure_ai():
    """é…ç½®AIå®¢æˆ·ç«¯"""
    api_key = os.getenv(AI_API_KEY_ENV)
    if not api_key:
        print(f"âŒ é”™è¯¯ï¼šæœªè®¾ç½® {AI_API_KEY_ENV} ç¯å¢ƒå˜é‡")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„APIå¯†é’¥")
        sys.exit(1)
    
    try:
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(AI_MODEL)
        print(f"âœ… AIé…ç½®æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹ï¼š{AI_MODEL}")
        return model
    except ImportError:
        print("âŒ é”™è¯¯ï¼šæœªå®‰è£… google-generativeai åº“")
        print("è¯·è¿è¡Œï¼špip install google-generativeai")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ AIé…ç½®å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)

def ai_technical_analysis(model, feature_name, prd_content):
    """ä½¿ç”¨AIè¿›è¡ŒæŠ€æœ¯åˆ†æ"""
    prompt = f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ€æœ¯æ¶æ„å¸ˆï¼Œéœ€è¦å°†ä»¥ä¸‹PRDè½¬æ¢ä¸ºè¯¦ç»†çš„æŠ€æœ¯å®ç°epicã€‚

åŠŸèƒ½åç§°ï¼š{feature_name}

PRDå†…å®¹ï¼š
{prd_content}

è¯·æä¾›ä»¥ä¸‹æŠ€æœ¯åˆ†æï¼ˆç”¨ä¸­æ–‡å›ç­”ï¼‰ï¼š

1. æ¶æ„å†³ç­–ï¼šå…³é”®æŠ€æœ¯å†³ç­–å’Œç†ç”±
2. æŠ€æœ¯æ ˆï¼šæ¨èçš„æŠ€æœ¯æ ˆé€‰æ‹©
3. å‰ç«¯ç»„ä»¶ï¼šéœ€è¦çš„UIç»„ä»¶å’Œäº¤äº’æ¨¡å¼
4. åç«¯æœåŠ¡ï¼šAPIè®¾è®¡å’Œæ•°æ®æ¨¡å‹
5. åŸºç¡€è®¾æ–½ï¼šéƒ¨ç½²å’Œæ‰©å±•è€ƒè™‘
6. å®ç°é˜¶æ®µï¼šå¼€å‘é˜¶æ®µåˆ’åˆ†
7. é£é™©ç¼“è§£ï¼šæ½œåœ¨é£é™©å’Œç¼“è§£ç­–ç•¥
8. æµ‹è¯•æ–¹æ³•ï¼šæµ‹è¯•ç­–ç•¥å’Œæ–¹æ³•
9. ä»»åŠ¡ç±»åˆ«ï¼šé«˜çº§ä»»åŠ¡åˆ†ç±»ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰
10. æ—¶é—´è¯„ä¼°ï¼šæ•´ä½“å¼€å‘æ—¶é—´çº¿
11. èµ„æºéœ€æ±‚ï¼šæ‰€éœ€çš„å¼€å‘èµ„æº
12. å…³é”®è·¯å¾„ï¼šå…³é”®çš„ä¾èµ–é¡¹ç›®

è¯·ä¸ºæ¯ä¸ªæ–¹é¢æä¾›å…·ä½“ã€å®ç”¨çš„å»ºè®®ã€‚
"""
    
    try:
        print("ğŸ¤– AIæ­£åœ¨åˆ†æPRDå¹¶ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆ...")
        response = model.generate_content(prompt)
        
        # è§£æAIå“åº”
        analysis_text = response.text
        
        # ç®€å•çš„æ–‡æœ¬è§£ææ¥æå–å„ä¸ªéƒ¨åˆ†
        analysis = {
            'architecture_decisions': extract_ai_section(analysis_text, 'æ¶æ„å†³ç­–'),
            'technology_stack': extract_ai_section(analysis_text, 'æŠ€æœ¯æ ˆ'),
            'frontend_components': extract_ai_section(analysis_text, 'å‰ç«¯ç»„ä»¶'),
            'backend_services': extract_ai_section(analysis_text, 'åç«¯æœåŠ¡'),
            'infrastructure': extract_ai_section(analysis_text, 'åŸºç¡€è®¾æ–½'),
            'implementation_phases': extract_ai_section(analysis_text, 'å®ç°é˜¶æ®µ'),
            'risk_mitigation': extract_ai_section(analysis_text, 'é£é™©ç¼“è§£'),
            'testing_approach': extract_ai_section(analysis_text, 'æµ‹è¯•æ–¹æ³•'),
            'task_categories': extract_ai_section(analysis_text, 'ä»»åŠ¡ç±»åˆ«'),
            'timeline_estimate': extract_ai_section(analysis_text, 'æ—¶é—´è¯„ä¼°'),
            'resource_requirements': extract_ai_section(analysis_text, 'èµ„æºéœ€æ±‚'),
            'critical_path': extract_ai_section(analysis_text, 'å…³é”®è·¯å¾„')
        }
        
        print("âœ… AIæŠ€æœ¯åˆ†æå®Œæˆï¼")
        return analysis
        
    except Exception as e:
        print(f"âŒ AIåˆ†æå¤±è´¥ï¼š{str(e)}")
        print("åˆ‡æ¢åˆ°äº¤äº’æ¨¡å¼...")
        return None

def extract_ai_section(text, section_name):
    """ä»AIå“åº”ä¸­æå–ç‰¹å®šç« èŠ‚çš„å†…å®¹"""
    lines = text.split('\n')
    content_lines = []
    in_section = False
    
    for line in lines:
        if section_name in line and ('ï¼š' in line or ':' in line):
            in_section = True
            # å¦‚æœåŒä¸€è¡Œæœ‰å†…å®¹ï¼Œæå–å®ƒ
            if 'ï¼š' in line:
                content = line.split('ï¼š', 1)[1].strip()
            elif ':' in line:
                content = line.split(':', 1)[1].strip()
            else:
                content = ''
            if content:
                content_lines.append(content)
        elif in_section and line.strip():
            if any(keyword in line for keyword in ['æ¶æ„å†³ç­–', 'æŠ€æœ¯æ ˆ', 'å‰ç«¯ç»„ä»¶', 'åç«¯æœåŠ¡', 'åŸºç¡€è®¾æ–½', 'å®ç°é˜¶æ®µ', 'é£é™©ç¼“è§£', 'æµ‹è¯•æ–¹æ³•', 'ä»»åŠ¡ç±»åˆ«', 'æ—¶é—´è¯„ä¼°', 'èµ„æºéœ€æ±‚', 'å…³é”®è·¯å¾„']):
                # æ–°çš„ç« èŠ‚å¼€å§‹
                break
            content_lines.append(line.strip())
        elif in_section and not line.strip():
            # ç©ºè¡Œï¼Œç»§ç»­
            continue
    
    result = ' '.join(content_lines).strip()
    return result if result else f"å¾…åˆ†æ{section_name}"

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å°†PRDè½¬æ¢ä¸ºæŠ€æœ¯å®ç°epic')
    parser.add_argument('feature_name', help='åŠŸèƒ½åç§°')
    parser.add_argument('--non-interactive', action='store_true', help='éäº¤äº’æ¨¡å¼')
    parser.add_argument('--ai', action='store_true', help='AIåä½œæ¨¡å¼')
    
    args = parser.parse_args()
    feature_name = args.feature_name
    
    # ç¡®å®šå·¥ä½œæ¨¡å¼
    if args.ai:
        mode = 'ai'
    elif args.non_interactive:
        mode = 'non-interactive'
    else:
        mode = 'interactive'
    
    print(f"\nğŸ”§ PRD Parse - å°†PRDè½¬æ¢ä¸ºEpic")
    print(f"åŠŸèƒ½åç§°: {feature_name}")
    print(f"å·¥ä½œæ¨¡å¼: {mode}")
    
    # 1. éªŒè¯åŠŸèƒ½åç§°æ ¼å¼
    valid, error_msg = validate_feature_name(feature_name)
    if not valid:
        print(error_msg)
        sys.exit(1)
    
    # 2. æ£€æŸ¥PRDæ˜¯å¦å­˜åœ¨
    prd_exists, prd_file = check_prd_exists(feature_name)
    if not prd_exists:
        print(f"âŒ PRDä¸å­˜åœ¨ï¼š{feature_name}. è¯·å…ˆè¿è¡Œï¼špython prd_new.py {feature_name}")
        sys.exit(1)
    
    # 3. éªŒè¯PRD frontmatter
    valid_prd, prd_content = validate_prd_frontmatter(prd_file)
    if not valid_prd:
        print(f"âŒ PRD frontmatteræ— æ•ˆï¼š{prd_content}")
        sys.exit(1)
    
    # 4. æ£€æŸ¥epicæ˜¯å¦å·²å­˜åœ¨
    epic_exists, epic_file = check_epic_exists(feature_name)
    if epic_exists:
        if mode == 'non-interactive':
            print(f"âš ï¸ Epic '{feature_name}' å·²å­˜åœ¨ï¼Œå°†è¦†ç›–ç°æœ‰æ–‡ä»¶")
        else:
            overwrite = input(f"âš ï¸ Epic '{feature_name}' å·²å­˜åœ¨ã€‚æ˜¯å¦è¦†ç›–ï¼Ÿ(yes/no): ")
            if overwrite.lower() not in ['yes', 'y']:
                print(f"æ“ä½œå·²å–æ¶ˆã€‚æŸ¥çœ‹ç°æœ‰epicï¼špython epic_show.py {feature_name}")
                sys.exit(0)
    
    # 5. ç¡®ä¿epicç›®å½•å­˜åœ¨
    success, epic_dir = ensure_epic_directory(feature_name)
    if not success:
        print(epic_dir)  # é”™è¯¯æ¶ˆæ¯
        sys.exit(1)
    
    # 6. æå–PRDä¿¡æ¯
    prd_description, prd_sections = extract_prd_info(prd_content)
    
    # 7. è·å–å½“å‰æ—¶é—´
    created_time = get_current_datetime()
    
    # 8. è¿›è¡ŒæŠ€æœ¯åˆ†æ
    if mode == 'ai':
        # AIåä½œæ¨¡å¼
        model = configure_ai()
        analysis = ai_technical_analysis(model, feature_name, prd_content)
        if analysis is None:
            # AIå¤±è´¥ï¼Œå›é€€åˆ°äº¤äº’æ¨¡å¼
            analysis = conduct_technical_analysis(feature_name, prd_sections, 'interactive')
    else:
        # äº¤äº’æˆ–éäº¤äº’æ¨¡å¼
        analysis = conduct_technical_analysis(feature_name, prd_sections, mode)
    
    # 9. åˆ›å»ºepicå†…å®¹
    content = create_epic_content(feature_name, prd_description, analysis, created_time)
    
    # 10. ä¿å­˜epic
    epic_file = epic_dir / "epic.md"
    success, error_msg = save_epic(epic_file, content)
    if not success:
        print(error_msg)
        sys.exit(1)
    
    # 11. æ˜¾ç¤ºåˆ›å»ºåæ‘˜è¦
    show_epic_creation_summary(feature_name, analysis, created_time, epic_file)

if __name__ == "__main__":
    main()